# ğŸ“ˆ Linear Regression from Scratch

A comprehensive implementation of linear regression using pure mathematical formulas and NumPy vectorized operations, without relying on built-in regression functions.

## ğŸ¯ Overview

This project demonstrates the mathematical foundations of linear regression by:
1. **Simulating data** with known parameters
2. **Implementing OLS formulas** using vectorized operations
3. **Recovering parameters** with high accuracy
4. **Visualizing results** comprehensively

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install numpy matplotlib
```

### Running the Analysis
Execute the three main steps in sequence:

1. **Step 1: Data Simulation**
   ```python
   python step1_simulation.py
   ```

2. **Step 2: Regression Calculation**
   ```python
   python step2_regression.py
   ```

3. **Step 3: Visualization**
   ```python
   python step3_visualization.py
   ```

## ğŸ“Š What This Project Does

### Step 1: Data Simulation
- Defines true parameters Bâ‚€ = 5.0, Bâ‚ = 2.5
- Generates 10,000 X values from normal distribution
- Adds controlled noise (Îµ ~ N(0, 0.5))
- Creates Y values: **Y = Bâ‚€ + Bâ‚X + Îµ**

### Step 2: Mathematical Implementation
Implements the exact OLS formulas:

**Slope Coefficient:**
```
Î²â‚ = Î£(xáµ¢ - xÌ„)(yáµ¢ - È³) / Î£(xáµ¢ - xÌ„)Â²
```

**Intercept:**
```
Î²â‚€ = È³ - Î²â‚xÌ„
```

### Step 3: Analysis & Visualization
Creates comprehensive plots:
- Scatter plot with regression lines (true vs estimated)
- Predicted vs actual values
- Residuals analysis
- Distribution of residuals

## ğŸ“ˆ Expected Results

With the default parameters, you should see:
- **Bâ‚€ estimation error**: < 0.01 (< 0.2%)
- **Bâ‚ estimation error**: < 0.01 (< 0.4%)
- **R-squared**: > 0.99
- **RMSE**: â‰ˆ 0.5 (noise level)

## ğŸ”§ Technical Implementation

### Key Features
- âœ… **No built-in regression functions** - Pure mathematical implementation
- âœ… **Vectorized operations** - No loops, efficient NumPy operations
- âœ… **Large sample handling** - Efficiently processes 10,000+ data points
- âœ… **Comprehensive validation** - Multiple accuracy metrics and visualizations

### Code Structure
```
ğŸ“ linear_regression_exercise/
â”œâ”€â”€ ğŸ“„ step1_simulation.py      # Data generation
â”œâ”€â”€ ğŸ“„ step2_regression.py      # OLS implementation
â”œâ”€â”€ ğŸ“„ step3_visualization.py   # Results analysis
â”œâ”€â”€ ğŸ“„ README.md               # This file
â””â”€â”€ ğŸ“„ PRD.md                  # Product Requirements Document
```

## ğŸ§® Mathematical Foundation

The implementation follows the standard Ordinary Least Squares (OLS) method:

1. **Calculate means**: xÌ„ = (1/n)Î£xáµ¢, È³ = (1/n)Î£yáµ¢
2. **Compute deviations**: (xáµ¢ - xÌ„), (yáµ¢ - È³)
3. **Apply formulas**: Use vectorized operations for efficient computation
4. **Validate results**: Compare estimated vs true parameters

## ğŸ“Š Sample Output

```
RESULTS COMPARISON:
==================================================
Parameter    True Value   Estimated    Error
--------------------------------------------------
B0 (Intercept) 5.000000     5.006758     0.006758
B1 (Slope)     2.500000     2.495734     0.004266

Percentage Errors:
  B0 error: 0.1351%
  B1 error: 0.1706%

Model Performance:
  R-squared: 0.996824
  Root Mean Square Error: 0.499891
```

## ğŸ¨ Visualizations Generated

1. **Data Points with Regression Lines**
   - Original data scatter plot
   - True regression line (red)
   - Estimated regression line (green dashed)

2. **Predicted vs Actual Values**
   - Scatter plot of predictions vs reality
   - Perfect prediction line for reference
   - RÂ² value displayed

3. **Residuals Analysis**
   - Residuals vs predicted values
   - Should show random scatter around zero

4. **Residuals Distribution**
   - Histogram of residuals
   - Should approximate normal distribution

## ğŸ”¬ Educational Value

This project teaches:
- **Mathematical foundations** of linear regression
- **Vectorized programming** techniques
- **Statistical validation** methods
- **Data visualization** best practices
- **Parameter estimation** concepts

## ğŸ› ï¸ Customization Options

You can modify these parameters in the code:

```python
# Simulation parameters
true_b0 = 5.0          # True intercept
true_b1 = 2.5          # True slope
n_samples = 10000      # Sample size
noise_std = 0.5        # Noise level
```

## ğŸ“š Dependencies

- **NumPy**: Mathematical operations and array handling
- **Matplotlib**: Data visualization and plotting

## ğŸ¤ Contributing

This is an educational exercise. Feel free to:
- Experiment with different parameters
- Add new visualizations
- Implement additional metrics
- Test with real-world datasets

## ğŸ“„ Documentation

- **README.md** - This file (user guide and overview)
- **PRD.md** - Product Requirements Document (detailed specifications)

## âš¡ Performance Notes

- **Efficient**: Uses vectorized NumPy operations
- **Scalable**: Handles large datasets (tested with 10,000+ points)
- **Fast**: Complete analysis typically runs in < 5 seconds

## ğŸ“ Learning Outcomes

After running this project, you will understand:
1. How linear regression works mathematically
2. The relationship between theory and implementation
3. How to validate statistical models
4. Effective data visualization techniques
5. Vectorized computation benefits

---

