# Linear Regression Analysis with R²

## Project Overview
This project demonstrates linear regression analysis using pure linear algebra (no sklearn), 
examining how error variance affects R² performance.

## What This Project Shows

### 1. The Relationship Between Error Variance and R²
**Simple Explanation**: Variance = how spread out points are from the average.
- Low variance → points close to the line → high R²
- High variance → points scattered everywhere → low R²

Think of it like shooting arrows at a target:
- All arrows near center = low variance
- Arrows scattered all over = high variance

### 2. Why Adding More Variables Doesn't Always Help
We compared models with 50 vs 70 variables and found that more isn't always better...


וריאנס = שונות.

זה מספר שמספר לנו כמה הנקודות מתפזרות מסביב לערך הממוצע.

אם כל הנקודות קרובות לממוצע → וריאנס קטן.

אם הנקודות עפות לכל הכיוונים → וריאנס גדול.

📌 דימוי:
דמייני שאת יורה חצים על לוח מטרה:

אם כולם קרובים למרכז → שונות קטנה.

אם החצים פזורים בכל הלוח → שונות גדולה.

🔹  מה קורה בגרף?

ציר X = שונות של השגיאה (כמה רעש הוספנו).

ציר Y = R² (כמה טוב המודל מסביר את הנתונים).

מה שרואים:

בהתחלה (שונות נמוכה) → R² קרוב ל־1 → המודל מסביר מעולה.

ככל שהשונות גדלה → R² יורד → המודל מאבד דיוק.

🔹 האם זה הגיוני? למה?

כן, זה מאוד הגיוני ✅

כי R² מודד כמה טוב הקו שלנו מתאים לנקודות:

אם יש מעט רעש → הנקודות צמודות לקו → קל למודל להסביר → R² גבוה.

אם יש הרבה רעש → הנקודות מתפזרות לכל מקום → קשה להסביר → R² נמוך.

📌 דוגמה יומיומית:
את רוצה לנבא מחיר דירה לפי הגודל שלה:

אם כל הדירות באמת עוקבות אחרי כלל ברור (כמו "מחיר = 10,000 ₪ לכל מ"ר") → R² קרוב ל־1.

אם יש בלגן (דירות באותו גודל נמכרות במחירים שונים מאוד) → וריאנס של השגיאה גדול → המודל לא מצליח להסביר טוב → R² קטן.

גרפים בתמונה מספר 2 ----

הכותרת: השוואה בין 50 משתנים ל־70 משתנים

הקו הכחול = מודל עם 50 משתנים.

הקו האדום = מודל עם 70 משתנים (כלומר הוספנו עוד 20).

ציר X = כמות הרעש (השונות σ).

ציר Y = R² (כמה טוב המודל מסביר את הנתונים).

מה רואים?

בהתחלה (מעט רעש): שני המודלים כמעט זהים, R² קרוב ל־1.

ככל שהרעש גדל: שניהם יורדים, אבל האדום (70 משתנים) לפעמים קצת יותר טוב מהכחול.

💡 דימוי:
תחשבי שיש לך מבחן:

עם 50 תשובות אפשר כבר להסביר טוב.

עם עוד 20 תשובות (אפילו אם חלקן סתם חזרות על קודמות), לפעמים זה נותן שיפור קטן.

🔹 למטה (הגרף השני)

הכותרת: כמה באמת הרווחנו מלהוסיף את ה־20 משתנים

ציר X = כמות הרעש.

ציר Y = השיפור (ההבדל בין R² של 70 משתנים לבין R² של 50 משתנים).

הקו הירוק:

אם הוא מעל האפס → שיפור קטן.

אם הוא מתחת לאפס → דווקא נהיה גרוע יותר.

מה רואים?

ברוב הזמן השיפור מאוד קטן (כמעט אפס).

לפעמים כשיש יותר רעש, השיפור טיפה גדל, אבל עדיין לא ממש דרמטי.

📝 סיכום לילד בן 6

עשינו מודל עם 50 משתנים.

הוספנו עוד 20 משתנים.

התוצאה: זה כמעט לא שינה כלום – לפעמים טיפה יותר טוב, לפעמים אפילו טיפה יותר גרוע.

כלומר: לא תמיד שווה להוסיף עוד משתנים – זה כמו לכתוב תשובות מיותרות במבחן.

מה מייצג הקו הירוק?

זה ההבדל בין R² עם 70 משתנים לבין R² עם 50 משתנים.

אם הקו מעל 0 → המודל עם 70 משתנים הצליח יותר.

אם הקו מתחת ל־0 → המודל עם 70 משתנים דווקא היה פחות טוב (!).

🔹 למה לפעמים יש עליות גדולות?

כשיש הרבה רעש, הוספת משתנים "מלאכותיים" לפעמים מאפשרת למודל "להתאים את עצמו" יותר טוב לרעש.

זה גורם ל־R² לעלות קצת → רואים קפיצה למעלה.

💡 זה כמו לנסות לנחש תשובות במבחן: אם יש לך יותר ניחושים, אולי תפגע יותר טוב במקרה.

🔹 למה לפעמים זה מתחת לאפס?

לפעמים ההוספה של משתנים מיותרים מבלבלת את המודל.

התוצאה: R² של המודל עם 70 משתנים יוצא אפילו יותר גרוע מהמודל עם 50 משתנים.

💡 זה כמו שמישהו במבחן כתב תשובה מיותרת שהכניסה טעות → הציון ירד.

🔹 מה זה אומר בפועל?

הוספת משתנים מיותרים לא מבטיחה שיפור.

לפעמים זה משפר טיפה (עליות למעלה).

לפעמים זה פוגע (נפילות מתחת לאפס).

בממוצע → רואים שהשיפור קטן מאוד, ולכן לא תמיד משתלם להוסיף משתנים.

------גרפים 3---------

החלק העליון – השוואה בין R² רגיל ל־Adjusted R²

שמאל (Regular R²):

כחול = מודל עם 50 משתנים.

אדום = מודל עם 70 משתנים.

R² תמיד נראה גבוה יותר כשמוסיפים משתנים → גם אם הם מיותרים.
💡 זה כמו לכתוב מלא תשובות במבחן – המורה סופר את כולן, גם אם חלק סתם.

ימין (Adjusted R²):

כאן עושים תיקון (עונש קטן).

אם הוספת משתנים סתם, רואים שהקו של 70 לא תמיד יותר טוב מה־50.
💡 זה כמו מורה חכם שאומר: “אל תעבוד עליי – אני סופר רק תשובות שעוזרות באמת”.

🔹 החלק התחתון – העונש (Penalty)

שמאל (50 משתנים):

גרף ירוק.

מראה את הפער בין R² רגיל ל־Adjusted R².

ככל שהרעש (variance) עולה → הפער גדל → המודל נענש יותר.

ימין (70 משתנים):

גרף ורוד.

רואים שהעונש אפילו יותר גדול כי הוספנו עוד משתנים מיותרים.
💡 זה כמו לקבל הורדה בציון כי ניסית לכתוב יותר מדי שטויות במבחן.

-----------גרפים 4
🔹 החלק השמאלי (Comprehensive Comparison)

כאן משווים את R² רגיל מול Adjusted R², גם עבור 50 משתנים וגם עבור 70.

כחול מלא = R² רגיל עם 50 משתנים.

כחול מקווקו = Adjusted R² עם 50 משתנים.

אדום מלא = R² רגיל עם 70 משתנים.

אדום מקווקו = Adjusted R² עם 70 משתנים.

מה רואים?

כל הקווים מתחילים קרוב ל־1 (כמעט מושלם) כשאין רעש.

ככל שהרעש גדל → כל הקווים יורדים.

ההבדל: הקווים המקווקווים (Adjusted R²) תמיד טיפה יותר נמוכים, כי יש בהם "עונש" על הוספת משתנים מיותרים.

💡 דימוי: זה כמו מבחן – גם אם תוסיף מלא משפטים סתם, הציון הגולמי (R² רגיל) אולי יראה טוב, אבל המורה החכם (Adjusted R²) יגיד: “לא מתרשם, זה סתם חפירות”.

🔹 החלק הימני (Adjusted R² Penalty)

כאן מסתכלים רק על ההבדל בין R² רגיל ל־Adjusted R².

כחול = מודל עם 50 משתנים.

אדום = מודל עם 70 משתנים.

הציר Y שלילי → זה ה"עונש" (כלומר כמה הורידו מהציון).

מה רואים?

כשיש מעט רעש → כמעט אין עונש (הקווים קרובים ל־0).

ככל שהרעש גדל → העונש נהיה יותר ויותר גדול.

למודל עם 70 משתנים (אדום) יש עונש יותר חזק מאשר למודל עם 50 משתנים.

💡 דימוי: מי שכתב 70 תשובות במבחן (חלקן מיותרות) חטף הורדה גדולה יותר בציון מהמורה, לעומת מי שכתב 50 תשובות.

# Feature Engineering: Creating 20 New Variables

## Variable Creation Strategy

We created 20 additional variables using **non-linear transformations** rather than simple linear combinations. Specifically: 5 squared terms (X₁², X₂², etc.), 5 square root terms (√|X₆|, √|X₇|, etc.), and 10 interaction terms (X₁×X₂, X₁×X₃, etc.). These are all **non-linear** transformations because they cannot be written as simple weighted sums of the original variables.

This approach is superior to using linear combinations (like X₁ + X₂ or 2×X₁ - 3×X₂) because linear combinations add no new information - the regression model can already capture any linear relationship between variables automatically. Non-linear features, however, allow the model to capture curved relationships, polynomial patterns, and variable interactions that a purely linear model would miss.

The result is genuine feature engineering that expands the model's capability to fit complex patterns, which is why we sometimes see meaningful improvements in R² when adding these 20 variables, especially when noise levels are low.


𝑌
זה מה שאנחנו רוצים לחזות / לנבא.
לדוגמה: ציון במבחן, מחיר של בית, משקל של ילד.

β (בטא)?
אלו המספרים (הכפתורים) שהמודל לומד כדי לדעת איך כל משתנה משפיע על 
𝑌



אפשר לחשוב על זה כמו מתכון לעוגה: כמה סוכר, כמה קמח, כמה חלב.
ה־
𝛽
β זה הכמויות.

📌 מה זה 𝑅2

 (R בריבוע)?

זה ציון בין 0 ל־1 שאומר לנו כמה טוב המודל מצליח להסביר את 
𝑌


אם 
𝑅=1

=1 → המודל מושלם, מנבא בדיוק.

אם 
𝑅=0

=0 → המודל לא יודע כלום, כמו לנחש באקראי.

אם 
𝑅=0.8
=0.8 → המודל מסביר 80% מהשינויים ב־


אפשר לחשוב על זה כמו:

אם יש ילד שזורק כדור – המודל מנסה לנחש איפה הוא יפול.


 זה הציון שלו: כמה קרוב הוא פוגע למקום הנכון.

סיכום בקטנה:

Y = מה שאני רוצה לנבא (המטרה).

β = כמה כל משתנה משפיע על 

 = כמה טוב המודל מסביר את הנתונים (0 = גרוע, 1 = מושלם).